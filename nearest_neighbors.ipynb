{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/fma_metadata/features.csv', index_col=0, header=[0, 1, 2])\n",
    "tracks = pd.read_csv('data/fma_metadata/tracks.csv', index_col=0, header=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENS = 'chroma_cens'\n",
    "CQT = 'chroma_cqt'\n",
    "STFT = 'chroma_stft'\n",
    "MFCC = 'mfcc'\n",
    "RMSE = 'rmse'\n",
    "BW = 'spectral_bandwidth'\n",
    "CENT = 'spectral_centroid'\n",
    "CONT = 'spectral_contrast'\n",
    "ROLLOFF = 'spectral_rolloff'\n",
    "TON = 'tonnetz'\n",
    "ZCR = 'zcr'\n",
    "all_features = [CENS,CQT,STFT,MFCC,RMSE,BW,CENT,CONT,ROLLOFF,TON,ZCR]\n",
    "\n",
    "class kNN(object):\n",
    "    def __init__(self,tracks,features):\n",
    "        self.tracks = tracks\n",
    "        self.features = features\n",
    "        self.small = tracks['set', 'subset'] <= 'small'\n",
    "        self.training = tracks['set', 'split'] == 'training'\n",
    "        self.validation = tracks['set', 'split'] == 'validation'\n",
    "        self.testing = tracks['set', 'split'] == 'test'\n",
    "    \n",
    "    \n",
    "    def datasplit(self,feature_array):\n",
    "        # takes an array of features [MFCC, CONT]\n",
    "        X_train_temp = self.features.loc[self.small & (self.training | self.validation), feature_array]\n",
    "        X_test_temp = self.features.loc[self.small & self.testing, feature_array]\n",
    "        y_train_temp = self.tracks.loc[self.small & (self.training | self.validation), ('track', 'genre_top')]\n",
    "        y_test_temp = self.tracks.loc[self.small & self.testing, ('track', 'genre_top')]\n",
    "        y_train = y_train_temp.dropna()\n",
    "        y_test = y_test_temp.dropna()\n",
    "        X_train = X_train_temp.drop(y_train_temp.drop(y_train.index).index)\n",
    "        X_test = X_test_temp.drop(y_test_temp.drop(y_test.index).index)\n",
    "        EXPERIMENTAL = self.tracks['track', 'genre_top'] == \"Experimental\"\n",
    "        X_train = X_train.drop(X_train.loc[EXPERIMENTAL].index)\n",
    "        y_train = y_train.drop(y_train.loc[EXPERIMENTAL].index)\n",
    "        X_test = X_test.drop(X_test.loc[EXPERIMENTAL].index)\n",
    "        y_test = y_test.drop(y_test.loc[EXPERIMENTAL].index)\n",
    "        return skl.utils.shuffle(X_train, y_train, random_state=42), X_test, y_test\n",
    "    \n",
    "    # given parameters achieves the highest score\n",
    "    def train(self, feature_array=[MFCC,CONT], k=25, weights=\"uniform\"):\n",
    "        (X_train, y_train), X_test, y_test = self.datasplit(feature_array)\n",
    "        scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "        scaler.fit_transform(X_train)\n",
    "        scaler.transform(X_test)\n",
    "        self.classifier = skl.neighbors.KNeighborsClassifier(n_neighbors=k, weights=weights).fit(X_train,y_train)\n",
    "        print(self.classifier)\n",
    "        print(\"Training Report: \", self.classifier.score(X_train,y_train))\n",
    "        print(skl.metrics.classification_report(y_train, self.classifier.predict(X_train)))\n",
    "        print()\n",
    "        print(\"Test Report: \", self.classifier.score(X_test,y_test))\n",
    "        print(skl.metrics.classification_report(y_test, self.classifier.predict(X_test)))\n",
    "        \n",
    "    def cross_validation(self,feature_array=[MFCC,CONT]):\n",
    "        (X_train, y_train), X_test, y_test = self.datasplit(feature_array)\n",
    "        scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "        scaler.fit_transform(X_train)\n",
    "        scaler.transform(X_test)\n",
    "        \n",
    "        scores = ['precision', 'recall']\n",
    "\n",
    "        for score in scores:\n",
    "            print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "            print()\n",
    "            \n",
    "            tuned_parameters = {'n_neighbors':[i for i in range(5,200)],'weights':['distance','uniform']}\n",
    "            clf = skl.model_selection.GridSearchCV(skl.neighbors.KNeighborsClassifier(), tuned_parameters, cv=3, scoring='%s_macro' % score)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            print(\"Best parameters set found on development set:\")\n",
    "            print()\n",
    "            print(clf.best_params_)\n",
    "            print()\n",
    "            print(\"Grid scores on development set:\")\n",
    "            print()\n",
    "            means = clf.cv_results_['mean_test_score']\n",
    "            stds = clf.cv_results_['std_test_score']\n",
    "            for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "                print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                      % (mean, std * 2, params))\n",
    "            print()\n",
    "\n",
    "            print(\"Detailed classification report:\")\n",
    "            print()\n",
    "            print(\"The model is trained on the full development set.\")\n",
    "            print(\"The scores are computed on the full evaluation set.\")\n",
    "            print()\n",
    "            y_true, y_pred = y_test, clf.predict(X_test)\n",
    "            print(skl.metrics.classification_report(y_true, y_pred))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=25, p=2,\n",
      "           weights='uniform')\n",
      "Training Report:  0.6923755836465095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.16      0.28        97\n",
      "          Classical       0.65      0.84      0.73      1143\n",
      "            Country       0.63      0.24      0.35       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.73      0.67      0.70      8533\n",
      "               Folk       0.59      0.70      0.64      2504\n",
      "            Hip-Hop       0.60      0.69      0.64      3229\n",
      "       Instrumental       0.54      0.26      0.35      1770\n",
      "      International       0.69      0.53      0.60      1261\n",
      "               Jazz       0.60      0.28      0.38       524\n",
      "Old-Time / Historic       0.90      0.93      0.92       499\n",
      "                Pop       0.62      0.08      0.14      2128\n",
      "               Rock       0.72      0.91      0.80     12718\n",
      "           Soul-RnB       1.00      0.08      0.14       132\n",
      "             Spoken       0.64      0.40      0.49       392\n",
      "\n",
      "          micro avg       0.69      0.69      0.69     35124\n",
      "          macro avg       0.66      0.45      0.48     35124\n",
      "       weighted avg       0.69      0.69      0.66     35124\n",
      "\n",
      "\n",
      "Test Report:  0.632436627004656\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.47      0.70      0.56        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.70      0.68      0.69       839\n",
      "               Folk       0.31      0.33      0.32       299\n",
      "            Hip-Hop       0.56      0.72      0.63       323\n",
      "       Instrumental       0.53      0.12      0.20       309\n",
      "      International       0.39      0.30      0.34       128\n",
      "               Jazz       0.77      0.43      0.55        47\n",
      "Old-Time / Historic       0.80      0.96      0.88        55\n",
      "                Pop       0.18      0.02      0.04       204\n",
      "               Rock       0.70      0.90      0.79      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.71      0.39      0.50        31\n",
      "\n",
      "          micro avg       0.63      0.63      0.63      3866\n",
      "          macro avg       0.41      0.37      0.37      3866\n",
      "       weighted avg       0.59      0.63      0.59      3866\n",
      "\n",
      "Wall time: 22min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn = kNN(tracks,features)\n",
    "knn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn = kNN(tracks,features)\n",
    "knn.cross_validation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
