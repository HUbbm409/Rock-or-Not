{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data/fma_metadata/tracks.csv to a simpler data/train_labels.csv file where the first column is the track_id and the second column is the target musical genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\defne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "C:\\Users\\defne\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\defne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "C:\\Users\\defne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "C:\\Users\\defne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "tracks = pd.read_csv('data/fma_metadata/tracks.csv', index_col=0, header=[0, 1])\n",
    "COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'), ('track', 'genres'), ('track', 'genres_all')]\n",
    "for column in COLUMNS:\n",
    "    tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "            ('album', 'date_created'), ('album', 'date_released'),\n",
    "            ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "            ('artist', 'active_year_end')]\n",
    "for column in COLUMNS:\n",
    "    tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "SUBSETS = ('small', 'medium', 'large')\n",
    "tracks['set', 'subset'] = tracks['set', 'subset'].astype('category', categories=SUBSETS, ordered=True)\n",
    "\n",
    "COLUMNS = [('track', 'genre_top'), ('track', 'license'), ('album', 'type'), ('album', 'information'), ('artist', 'bio')]\n",
    "for column in COLUMNS:\n",
    "    tracks[column] = tracks[column].astype('category')\n",
    "\n",
    "# Faulty MP3 train files (https://github.com/mdeff/fma/issues/8).\n",
    "# MP3 train file IDs with 0 second of audio.\n",
    "FILES_TRAIN_NO_AUDIO = [1486, 5574, 65753, 80391, 98558, 98559, 98560, 98571,\n",
    "                        99134, 105247, 108925, 126981, 127336, 133297, 143992]\n",
    "# MP3 train file IDs with less than 30 seconds of audio.\n",
    "FILES_TRAIN_FAULTY = FILES_TRAIN_NO_AUDIO + [98565, 98566, 98567,\n",
    "                                             98568, 98569, 108924]\n",
    "\n",
    "subset = tracks.index[tracks['set', 'subset'] <= 'medium']\n",
    "labels = tracks.loc[subset, ('track', 'genre_top')]\n",
    "labels.name = 'genre'\n",
    "for i in FILES_TRAIN_FAULTY:\n",
    "    if i in labels.index:\n",
    "        labels = labels.drop(i)\n",
    "train_labels = labels.sample(frac=0.8)\n",
    "temp_labels = labels.drop(train_labels.index)\n",
    "valid_labels = temp_labels.sample(frac=0.5)\n",
    "test_labels = test_labels = temp_labels.drop(valid_labels.index)\n",
    "labels.to_csv('data/labels_medium.csv', header=True)\n",
    "train_labels.to_csv('data/train_labels_medium.csv', header=True)\n",
    "valid_labels.to_csv('data/valid_labels_medium.csv', header=True)\n",
    "test_labels.to_csv('data/test_labels_medium.csv', header=True)\n",
    "\n",
    "features = pd.read_csv('data/features.csv', index_col=0, header=[0, 1, 2])[:25000]\n",
    "train_features = features.loc[train_labels.index]\n",
    "valid_features = features.loc[valid_labels.index]\n",
    "test_features = features.loc[test_labels.index]\n",
    "\n",
    "train_features.to_csv('data/train_features_medium.csv', header=True)\n",
    "valid_features.to_csv('data/valid_features_medium.csv', header=True)\n",
    "test_features.to_csv('data/test_features_medium.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music Genres: Electronic Hip-Hop Rock Folk Instrumental Pop International Experimental Classical Old-Time / Historic Country Jazz Soul-RnB Blues Spoken Easy Listening\n",
      "Train:  19983\n",
      "Valid:  2498\n",
      "Test:  2498\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-699e972595f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Standardize features by removing the mean and scaling to unit variance.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \"\"\"\n\u001b[0;32m    611\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m--> 612\u001b[1;33m                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_labels = pd.read_csv('data/train_labels_medium.csv')\n",
    "valid_labels = pd.read_csv('data/valid_labels_medium.csv')\n",
    "test_labels = pd.read_csv('data/test_labels_medium.csv')\n",
    "\n",
    "train_features = pd.read_csv('data/train_features_medium.csv', index_col=0, header=[0, 1, 2])\n",
    "valid_features = pd.read_csv('data/valid_features_medium.csv', index_col=0, header=[0, 1, 2])\n",
    "test_features = pd.read_csv('data/test_features_medium.csv', index_col=0, header=[0, 1, 2])\n",
    "\n",
    "print('Music Genres:', *train_labels.genre.unique())\n",
    "print(\"Train: \",train_labels.genre.count())\n",
    "print(\"Valid: \",valid_labels.genre.count())\n",
    "print(\"Test: \",test_labels.genre.count())\n",
    "\n",
    "train_features.index = pd.Index((int(i) for i in train_features.index), name='track_id')\n",
    "\n",
    "train_features.sort_index(inplace=True)\n",
    "valid_features.sort_index(inplace=True)\n",
    "test_features.sort_index(inplace=True)\n",
    "\n",
    "train_features, train_labels = shuffle(train_features, train_labels, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = StandardScaler(copy=False)\n",
    "scaler.fit_transform(train_features)\n",
    "scaler.transform(valid_features)\n",
    "\n",
    "# Train the classifier and make predictions.\n",
    "clf = SVC(kernel='rbf', probability=True)\n",
    "clf.fit(train_features, train_labels)\n",
    "y_test = clf.predict_proba(valid_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
