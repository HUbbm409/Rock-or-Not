{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import ast\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import librosa, librosa.display\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/fma_metadata/features.csv', index_col=0, header=[0, 1, 2])\n",
    "tracks = pd.read_csv('data/fma_metadata/tracks.csv', index_col=0, header=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns():\n",
    "    feature_sizes = dict(chroma_stft=12, chroma_cqt=12, chroma_cens=12,\n",
    "                         tonnetz=6, mfcc=20, rmse=1, zcr=1,\n",
    "                         spectral_centroid=1, spectral_bandwidth=1,\n",
    "                         spectral_contrast=7, spectral_rolloff=1)\n",
    "    moments = ('mean', 'std', 'skew', 'kurtosis', 'median', 'min', 'max')\n",
    "\n",
    "    columns = []\n",
    "    for name, size in feature_sizes.items():\n",
    "        for moment in moments:\n",
    "            it = ((name, moment, '{:02d}'.format(i+1)) for i in range(size))\n",
    "            columns.extend(it)\n",
    "\n",
    "    names = ('feature', 'statistics', 'number')\n",
    "    columns = pd.MultiIndex.from_tuples(columns, names=names)\n",
    "\n",
    "    # More efficient to slice if indexes are sorted.\n",
    "    return columns.sort_values()\n",
    "\n",
    "\n",
    "def compute_features(filepath):\n",
    "\n",
    "    features = pd.Series(index=columns(), dtype=np.float32)\n",
    "\n",
    "    def feature_stats(name, values):\n",
    "        features[name, 'mean'] = np.mean(values, axis=1)\n",
    "        features[name, 'std'] = np.std(values, axis=1)\n",
    "        features[name, 'skew'] = stats.skew(values, axis=1)\n",
    "        features[name, 'kurtosis'] = stats.kurtosis(values, axis=1)\n",
    "        features[name, 'median'] = np.median(values, axis=1)\n",
    "        features[name, 'min'] = np.min(values, axis=1)\n",
    "        features[name, 'max'] = np.max(values, axis=1)\n",
    "\n",
    "    x, sr = librosa.load(filepath, sr=None, mono=True)  # kaiser_fast\n",
    "    f = librosa.feature.zero_crossing_rate(x, frame_length=2048, hop_length=512)\n",
    "    feature_stats('zcr', f)\n",
    "\n",
    "    cqt = np.abs(librosa.cqt(x, sr=sr, hop_length=512, bins_per_octave=12,\n",
    "                                 n_bins=7*12, tuning=None))\n",
    "\n",
    "    f = librosa.feature.chroma_cqt(C=cqt, n_chroma=12, n_octaves=7)\n",
    "    feature_stats('chroma_cqt', f)\n",
    "    f = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
    "    feature_stats('chroma_cens', f)\n",
    "    f = librosa.feature.tonnetz(chroma=f)\n",
    "    feature_stats('tonnetz', f)\n",
    "\n",
    "    stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "\n",
    "    f = librosa.feature.chroma_stft(S=stft**2, n_chroma=12)\n",
    "    feature_stats('chroma_stft', f)\n",
    "\n",
    "    f = librosa.feature.rmse(S=stft)\n",
    "    feature_stats('rmse', f)\n",
    "\n",
    "    f = librosa.feature.spectral_centroid(S=stft)\n",
    "    feature_stats('spectral_centroid', f)\n",
    "    f = librosa.feature.spectral_bandwidth(S=stft)\n",
    "    feature_stats('spectral_bandwidth', f)\n",
    "    f = librosa.feature.spectral_contrast(S=stft, n_bands=6)\n",
    "    feature_stats('spectral_contrast', f)\n",
    "    f = librosa.feature.spectral_rolloff(S=stft)\n",
    "    feature_stats('spectral_rolloff', f)\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "\n",
    "    #plt.figure(figsize=(10, 4))\n",
    "    #librosa.display.specshow(librosa.power_to_db(S = mel, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "    #plt.colorbar(format='%+2.0f dB')\n",
    "    #plt.title('Mel spectrogram')\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    f = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "    feature_stats('mfcc', f)\n",
    "    return [features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENS = 'chroma_cens'\n",
    "CQT = 'chroma_cqt'\n",
    "STFT = 'chroma_stft'\n",
    "MFCC = 'mfcc'\n",
    "RMSE = 'rmse'\n",
    "BW = 'spectral_bandwidth'\n",
    "CENT = 'spectral_centroid'\n",
    "CONT = 'spectral_contrast'\n",
    "ROLLOFF = 'spectral_rolloff'\n",
    "TON = 'tonnetz'\n",
    "ZCR = 'zcr'\n",
    "all_features = [CENS,CQT,STFT,MFCC,RMSE,BW,CENT,CONT,ROLLOFF,TON,ZCR]\n",
    "\n",
    "class Ridge(object):\n",
    "    def __init__(self,tracks,features):\n",
    "        self.tracks = tracks\n",
    "        self.features = features\n",
    "        self.small = tracks['set', 'subset'] <= 'small'\n",
    "        self.training = tracks['set', 'split'] == 'training'\n",
    "        self.validation = tracks['set', 'split'] == 'validation'\n",
    "        self.testing = tracks['set', 'split'] == 'test'\n",
    "\n",
    "    def datasplit(self,feature_array):\n",
    "        # takes an array of features [MFCC, CONT]\n",
    "        X_train_temp = self.features.loc[self.small & (self.training | self.validation), feature_array]\n",
    "        X_test_temp = self.features.loc[self.small & self.testing, feature_array]\n",
    "        y_train_temp = self.tracks.loc[self.small & (self.training | self.validation), ('track', 'genre_top')]\n",
    "        y_test_temp = self.tracks.loc[self.small & self.testing, ('track', 'genre_top')]\n",
    "        y_train = y_train_temp.dropna()\n",
    "        y_test = y_test_temp.dropna()\n",
    "        X_train = X_train_temp.drop(y_train_temp.drop(y_train.index).index)\n",
    "        X_test = X_test_temp.drop(y_test_temp.drop(y_test.index).index)\n",
    "        EXPERIMENTAL = self.tracks['track', 'genre_top'] == \"Experimental\"\n",
    "        X_train = X_train.drop(X_train.loc[EXPERIMENTAL].index)\n",
    "        y_train = y_train.drop(y_train.loc[EXPERIMENTAL].index)\n",
    "        X_test = X_test.drop(X_test.loc[EXPERIMENTAL].index)\n",
    "        y_test = y_test.drop(y_test.loc[EXPERIMENTAL].index)\n",
    "        return skl.utils.shuffle(X_train, y_train, random_state=42), X_test, y_test\n",
    "\n",
    "    def train(self):\n",
    "        (X_train, y_train), X_test, y_test = self.datasplit(all_features)\n",
    "        self.ridge = skl.linear_model.RidgeClassifierCV().fit(X_train, y_train)\n",
    "        print(\"Training Report\")\n",
    "        print(sklearn.metrics.classification_report(y_train, self.ridge.predict(X_train)))\n",
    "        print()\n",
    "        print(\"Test Report\")\n",
    "        print(sklearn.metrics.classification_report(y_test, self.ridge.predict(X_test)))\n",
    "        \n",
    "    def test(self, audio_feature):\n",
    "        print(self.ridge.predict(audio_feature))\n",
    "        \n",
    "class SVM(object):\n",
    "    def __init__(self,tracks,features):\n",
    "        self.tracks = tracks\n",
    "        self.features = features\n",
    "        self.small = tracks['set', 'subset'] <= 'small'\n",
    "        self.training = tracks['set', 'split'] == 'training'\n",
    "        self.validation = tracks['set', 'split'] == 'validation'\n",
    "        self.testing = tracks['set', 'split'] == 'test'\n",
    "    \n",
    "    \n",
    "    def datasplit(self,feature_array):\n",
    "        # takes an array of features [MFCC, CONT]\n",
    "        X_train_temp = self.features.loc[self.small & (self.training | self.validation), feature_array]\n",
    "        X_test_temp = self.features.loc[self.small & self.testing, feature_array]\n",
    "        y_train_temp = self.tracks.loc[self.small & (self.training | self.validation), ('track', 'genre_top')]\n",
    "        y_test_temp = self.tracks.loc[self.small & self.testing, ('track', 'genre_top')]\n",
    "        y_train = y_train_temp.dropna()\n",
    "        y_test = y_test_temp.dropna()\n",
    "        X_train = X_train_temp.drop(y_train_temp.drop(y_train.index).index)\n",
    "        X_test = X_test_temp.drop(y_test_temp.drop(y_test.index).index)\n",
    "        EXPERIMENTAL = self.tracks['track', 'genre_top'] == \"Experimental\"\n",
    "        X_train = X_train.drop(X_train.loc[EXPERIMENTAL].index)\n",
    "        y_train = y_train.drop(y_train.loc[EXPERIMENTAL].index)\n",
    "        X_test = X_test.drop(X_test.loc[EXPERIMENTAL].index)\n",
    "        y_test = y_test.drop(y_test.loc[EXPERIMENTAL].index)\n",
    "        return skl.utils.shuffle(X_train, y_train, random_state=42), X_test, y_test\n",
    "\n",
    "    def train(self, feature_array, c, g):\n",
    "        (X_train, y_train), X_test, y_test = self.datasplit(feature_array)\n",
    "        scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "        scaler.fit_transform(X_train)\n",
    "        scaler.transform(X_test)\n",
    "        self.ridge = skl.svm.SVC(kernel = \"rbf\", C = c, gamma = g).fit(X_train, y_train)\n",
    "        #print(\"Training Report\")\n",
    "        print(\"Train Accuracy: \", self.ridge.score(X_train, y_train))\n",
    "        print()\n",
    "        #print(sklearn.metrics.classification_report(y_train, self.ridge.predict(X_train)))\n",
    "        print()\n",
    "        #print(\"Test Report\")\n",
    "        print(\"Test Accuracy: \", self.ridge.score(X_test, y_test))\n",
    "        #print(sklearn.metrics.classification_report(y_test, self.ridge.predict(X_test)))\n",
    "        \n",
    "    def test(self, audio_feature):\n",
    "        print(self.ridge.predict(audio_feature))\n",
    "        \n",
    "    def cv(self, feature_array):\n",
    "        (X_train, y_train), X_test, y_test = self.datasplit(feature_array)\n",
    "        scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "        scaler.fit_transform(X_train)\n",
    "        scaler.transform(X_test)\n",
    "        tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1, 1e0, 1e1],\n",
    "                             'C': [1, 10]},\n",
    "                            {'kernel': ['linear'], 'C': [1, 10]}]\n",
    "\n",
    "        scores = ['precision', 'recall']\n",
    "\n",
    "        for score in scores:\n",
    "            print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "            print()\n",
    "\n",
    "            clf = skl.model_selection.GridSearchCV(skl.svm.SVC(), tuned_parameters, cv=3, scoring='%s_macro' % score)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            print(\"Best parameters set found on development set:\")\n",
    "            print()\n",
    "            print(clf.best_params_)\n",
    "            print()\n",
    "            print(\"Grid scores on development set:\")\n",
    "            print()\n",
    "            means = clf.cv_results_['mean_test_score']\n",
    "            stds = clf.cv_results_['std_test_score']\n",
    "            for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "                print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                      % (mean, std * 2, params))\n",
    "            print()\n",
    "\n",
    "            print(\"Detailed classification report:\")\n",
    "            print()\n",
    "            print(\"The model is trained on the full development set.\")\n",
    "            print(\"The scores are computed on the full evaluation set.\")\n",
    "            print()\n",
    "            y_true, y_pred = y_test, clf.predict(X_test)\n",
    "            print(classification_report(y_true, y_pred))\n",
    "            print()\n",
    "            \n",
    "class LR(object):\n",
    "    def __init__(self,tracks,features):\n",
    "        self.tracks = tracks\n",
    "        self.features = features\n",
    "        self.small = tracks['set', 'subset'] <= 'small'\n",
    "        self.training = tracks['set', 'split'] == 'training'\n",
    "        self.validation = tracks['set', 'split'] == 'validation'\n",
    "        self.testing = tracks['set', 'split'] == 'test'\n",
    "    \n",
    "    \n",
    "    def datasplit(self,feature_array):\n",
    "        # takes an array of features [MFCC, CONT]\n",
    "        X_train_temp = self.features.loc[self.small & (self.training | self.validation), feature_array]\n",
    "        X_test_temp = self.features.loc[self.small & self.testing, feature_array]\n",
    "        y_train_temp = self.tracks.loc[self.small & (self.training | self.validation), ('track', 'genre_top')]\n",
    "        y_test_temp = self.tracks.loc[self.small & self.testing, ('track', 'genre_top')]\n",
    "        y_train = y_train_temp.dropna()\n",
    "        y_test = y_test_temp.dropna()\n",
    "        X_train = X_train_temp.drop(y_train_temp.drop(y_train.index).index)\n",
    "        X_test = X_test_temp.drop(y_test_temp.drop(y_test.index).index)\n",
    "        EXPERIMENTAL = self.tracks['track', 'genre_top'] == \"Experimental\"\n",
    "        X_train = X_train.drop(X_train.loc[EXPERIMENTAL].index)\n",
    "        y_train = y_train.drop(y_train.loc[EXPERIMENTAL].index)\n",
    "        X_test = X_test.drop(X_test.loc[EXPERIMENTAL].index)\n",
    "        y_test = y_test.drop(y_test.loc[EXPERIMENTAL].index)\n",
    "        return skl.utils.shuffle(X_train, y_train, random_state=42), X_test, y_test\n",
    "\n",
    "    def train(self, feature_array):\n",
    "        (X_train, y_train), X_test, y_test = self.datasplit(feature_array)\n",
    "        self.lr = skl.linear_model.LogisticRegression().fit(X_train, y_train)\n",
    "        print(\"Training Report\")\n",
    "        print(\"Train Accuracy: \", self.lr.score(X_train, y_train))\n",
    "        print(sklearn.metrics.classification_report(y_train, self.lr.predict(X_train)))\n",
    "        print()\n",
    "        print(\"Test Report\")\n",
    "        print(\"Test Accuracy: \", self.ridge.score(X_test, y_test))\n",
    "        print(sklearn.metrics.classification_report(y_test, self.lr.predict(X_test)))\n",
    "        \n",
    "    def test(self, audio_feature):\n",
    "        print(self.ridge.predict(audio_feature))\n",
    "        \n",
    "    def cv(self, feature_array):\n",
    "        (X_train, y_train), X_test, y_test = self.datasplit(feature_array)\n",
    "        \n",
    "        #[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "        tuned_parameters = [{\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"], \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}]\n",
    "\n",
    "        scores = ['precision', 'recall']\n",
    "\n",
    "        for score in scores:\n",
    "            print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "            print()\n",
    "\n",
    "            clf = skl.model_selection.GridSearchCV(skl.linear_model.LogisticRegression(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            print(\"Best parameters set found on development set:\")\n",
    "            print()\n",
    "            print(clf.best_params_)\n",
    "            print()\n",
    "            print(\"Grid scores on development set:\")\n",
    "            print()\n",
    "            means = clf.cv_results_['mean_test_score']\n",
    "            stds = clf.cv_results_['std_test_score']\n",
    "            for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "                print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                      % (mean, std * 2, params))\n",
    "            print()\n",
    "\n",
    "            print(\"Detailed classification report:\")\n",
    "            print()\n",
    "            print(\"The model is trained on the full development set.\")\n",
    "            print(\"The scores are computed on the full evaluation set.\")\n",
    "            print()\n",
    "            y_true, y_pred = y_test, clf.predict(X_test)\n",
    "            print(classification_report(y_true, y_pred))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        97\n",
      "          Classical       0.75      0.79      0.77      1143\n",
      "            Country       0.00      0.00      0.00       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.64      0.82      0.72      8533\n",
      "               Folk       0.61      0.56      0.58      2504\n",
      "            Hip-Hop       0.69      0.57      0.63      3229\n",
      "       Instrumental       0.65      0.17      0.27      1770\n",
      "      International       0.85      0.17      0.28      1261\n",
      "               Jazz       1.00      0.02      0.03       524\n",
      "Old-Time / Historic       0.88      0.90      0.89       499\n",
      "                Pop       0.57      0.03      0.05      2128\n",
      "               Rock       0.69      0.91      0.78     12718\n",
      "           Soul-RnB       0.00      0.00      0.00       132\n",
      "             Spoken       0.56      0.14      0.23       392\n",
      "\n",
      "          micro avg       0.68      0.68      0.68     35124\n",
      "          macro avg       0.53      0.34      0.35     35124\n",
      "       weighted avg       0.67      0.68      0.63     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.64      0.61      0.62        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.61      0.83      0.71       839\n",
      "               Folk       0.34      0.24      0.28       299\n",
      "            Hip-Hop       0.72      0.60      0.65       323\n",
      "       Instrumental       0.65      0.06      0.10       309\n",
      "      International       0.40      0.03      0.06       128\n",
      "               Jazz       1.00      0.02      0.04        47\n",
      "Old-Time / Historic       0.81      0.95      0.87        55\n",
      "                Pop       0.00      0.00      0.00       204\n",
      "               Rock       0.64      0.90      0.75      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.50      0.10      0.16        31\n",
      "\n",
      "          micro avg       0.62      0.62      0.62      3866\n",
      "          macro avg       0.42      0.29      0.28      3866\n",
      "       weighted avg       0.57      0.62      0.55      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rgd = Ridge(tracks, features)\n",
    "rgd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rock']\n"
     ]
    }
   ],
   "source": [
    "audio_features = compute_features('data/080517.wav')\n",
    "rgd.test(audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVM(tracks, features)\n",
    "svm.cv([MFCC, CENT, CONT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.18      0.30        97\n",
      "          Classical       0.93      0.89      0.91      1143\n",
      "            Country       1.00      0.13      0.23       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.76      0.91      0.83      8533\n",
      "               Folk       0.77      0.75      0.76      2504\n",
      "            Hip-Hop       0.84      0.74      0.79      3229\n",
      "       Instrumental       0.79      0.55      0.65      1770\n",
      "      International       0.89      0.61      0.72      1261\n",
      "               Jazz       0.90      0.45      0.60       524\n",
      "Old-Time / Historic       1.00      0.99      0.99       499\n",
      "                Pop       0.87      0.33      0.48      2128\n",
      "               Rock       0.82      0.93      0.88     12718\n",
      "           Soul-RnB       1.00      0.02      0.03       132\n",
      "             Spoken       0.79      0.77      0.78       392\n",
      "\n",
      "          micro avg       0.81      0.81      0.81     35124\n",
      "          macro avg       0.82      0.55      0.60     35124\n",
      "       weighted avg       0.82      0.81      0.80     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.77      0.83      0.80        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.63      0.85      0.72       839\n",
      "               Folk       0.38      0.30      0.33       299\n",
      "            Hip-Hop       0.72      0.69      0.71       323\n",
      "       Instrumental       0.55      0.19      0.28       309\n",
      "      International       0.63      0.34      0.44       128\n",
      "               Jazz       0.80      0.43      0.56        47\n",
      "Old-Time / Historic       0.96      0.96      0.96        55\n",
      "                Pop       0.10      0.02      0.03       204\n",
      "               Rock       0.73      0.89      0.81      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.61      0.45      0.52        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.41      3866\n",
      "       weighted avg       0.62      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION\n",
    "\n",
    "CENS = 'chroma_cens'\n",
    "CQT = 'chroma_cqt'\n",
    "STFT = 'chroma_stft'\n",
    "MFCC = 'mfcc'\n",
    "RMSE = 'rmse'\n",
    "BW = 'spectral_bandwidth'\n",
    "CENT = 'spectral_centroid'\n",
    "CONT = 'spectral_contrast'\n",
    "ROLLOFF = 'spectral_rolloff'\n",
    "TON = 'tonnetz'\n",
    "ZCR = 'zcr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report\n",
      "0.846543673841\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.33      0.50        97\n",
      "          Classical       0.95      0.92      0.94      1143\n",
      "            Country       1.00      0.31      0.48       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.80      0.93      0.86      8533\n",
      "               Folk       0.81      0.79      0.80      2504\n",
      "            Hip-Hop       0.87      0.79      0.83      3229\n",
      "       Instrumental       0.85      0.64      0.73      1770\n",
      "      International       0.92      0.67      0.78      1261\n",
      "               Jazz       0.94      0.60      0.73       524\n",
      "Old-Time / Historic       1.00      0.99      1.00       499\n",
      "                Pop       0.92      0.45      0.60      2128\n",
      "               Rock       0.85      0.95      0.90     12718\n",
      "           Soul-RnB       1.00      0.13      0.23       132\n",
      "             Spoken       0.84      0.85      0.85       392\n",
      "\n",
      "          micro avg       0.85      0.85      0.85     35124\n",
      "          macro avg       0.85      0.62      0.68     35124\n",
      "       weighted avg       0.85      0.85      0.84     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.675892395241\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.76      0.84      0.80        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.64      0.84      0.73       839\n",
      "               Folk       0.40      0.31      0.35       299\n",
      "            Hip-Hop       0.72      0.71      0.72       323\n",
      "       Instrumental       0.56      0.21      0.31       309\n",
      "      International       0.64      0.35      0.45       128\n",
      "               Jazz       0.77      0.43      0.55        47\n",
      "Old-Time / Historic       0.85      0.96      0.91        55\n",
      "                Pop       0.16      0.04      0.07       204\n",
      "               Rock       0.74      0.89      0.81      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.61      0.45      0.52        31\n",
      "\n",
      "          micro avg       0.68      0.68      0.68      3866\n",
      "          macro avg       0.46      0.40      0.41      3866\n",
      "       weighted avg       0.63      0.68      0.64      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC ONLY\n",
      "Training Report\n",
      "0.813944880993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.28      0.44        97\n",
      "          Classical       0.93      0.90      0.92      1143\n",
      "            Country       1.00      0.23      0.38       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.75      0.91      0.82      8533\n",
      "               Folk       0.78      0.75      0.76      2504\n",
      "            Hip-Hop       0.84      0.74      0.79      3229\n",
      "       Instrumental       0.79      0.57      0.66      1770\n",
      "      International       0.90      0.61      0.73      1261\n",
      "               Jazz       0.92      0.50      0.65       524\n",
      "Old-Time / Historic       0.99      0.99      0.99       499\n",
      "                Pop       0.91      0.36      0.51      2128\n",
      "               Rock       0.83      0.93      0.88     12718\n",
      "           Soul-RnB       1.00      0.07      0.13       132\n",
      "             Spoken       0.84      0.78      0.81       392\n",
      "\n",
      "          micro avg       0.81      0.81      0.81     35124\n",
      "          macro avg       0.83      0.57      0.63     35124\n",
      "       weighted avg       0.82      0.81      0.80     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.658044490429\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.67      0.78      0.72        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.61      0.82      0.70       839\n",
      "               Folk       0.39      0.28      0.32       299\n",
      "            Hip-Hop       0.72      0.68      0.70       323\n",
      "       Instrumental       0.49      0.19      0.27       309\n",
      "      International       0.62      0.29      0.39       128\n",
      "               Jazz       0.72      0.38      0.50        47\n",
      "Old-Time / Historic       0.84      0.96      0.90        55\n",
      "                Pop       0.14      0.03      0.05       204\n",
      "               Rock       0.73      0.89      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.68      0.42      0.52        31\n",
      "\n",
      "          micro avg       0.66      0.66      0.66      3866\n",
      "          macro avg       0.44      0.38      0.39      3866\n",
      "       weighted avg       0.61      0.66      0.61      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC ONLY\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT\n",
      "Training Report\n",
      "0.816962760506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.29      0.45        97\n",
      "          Classical       0.93      0.91      0.92      1143\n",
      "            Country       1.00      0.26      0.41       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.76      0.91      0.83      8533\n",
      "               Folk       0.78      0.75      0.77      2504\n",
      "            Hip-Hop       0.83      0.75      0.79      3229\n",
      "       Instrumental       0.81      0.57      0.67      1770\n",
      "      International       0.91      0.62      0.74      1261\n",
      "               Jazz       0.91      0.51      0.65       524\n",
      "Old-Time / Historic       0.99      0.99      0.99       499\n",
      "                Pop       0.89      0.37      0.52      2128\n",
      "               Rock       0.83      0.93      0.88     12718\n",
      "           Soul-RnB       1.00      0.08      0.14       132\n",
      "             Spoken       0.84      0.78      0.81       392\n",
      "\n",
      "          micro avg       0.82      0.82      0.82     35124\n",
      "          macro avg       0.83      0.58      0.64     35124\n",
      "       weighted avg       0.82      0.82      0.81     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.659855147439\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.66      0.77      0.71        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.61      0.82      0.70       839\n",
      "               Folk       0.37      0.27      0.31       299\n",
      "            Hip-Hop       0.71      0.68      0.70       323\n",
      "       Instrumental       0.53      0.20      0.29       309\n",
      "      International       0.62      0.28      0.39       128\n",
      "               Jazz       0.69      0.38      0.49        47\n",
      "Old-Time / Historic       0.83      0.95      0.88        55\n",
      "                Pop       0.17      0.03      0.06       204\n",
      "               Rock       0.73      0.89      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.70      0.45      0.55        31\n",
      "\n",
      "          micro avg       0.66      0.66      0.66      3866\n",
      "          macro avg       0.44      0.38      0.39      3866\n",
      "       weighted avg       0.61      0.66      0.62      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CENT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Training Report\n",
      "0.849106024371\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.34      0.51        97\n",
      "          Classical       0.96      0.92      0.94      1143\n",
      "            Country       1.00      0.34      0.50       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.80      0.93      0.86      8533\n",
      "               Folk       0.81      0.80      0.80      2504\n",
      "            Hip-Hop       0.87      0.79      0.83      3229\n",
      "       Instrumental       0.86      0.65      0.74      1770\n",
      "      International       0.93      0.67      0.78      1261\n",
      "               Jazz       0.94      0.61      0.74       524\n",
      "Old-Time / Historic       1.00      0.99      1.00       499\n",
      "                Pop       0.91      0.45      0.61      2128\n",
      "               Rock       0.86      0.95      0.90     12718\n",
      "           Soul-RnB       1.00      0.16      0.27       132\n",
      "             Spoken       0.84      0.85      0.85       392\n",
      "\n",
      "          micro avg       0.85      0.85      0.85     35124\n",
      "          macro avg       0.85      0.63      0.69     35124\n",
      "       weighted avg       0.86      0.85      0.84     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.676409725815\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.77      0.84      0.80        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.64      0.84      0.73       839\n",
      "               Folk       0.39      0.29      0.33       299\n",
      "            Hip-Hop       0.72      0.71      0.71       323\n",
      "       Instrumental       0.54      0.22      0.31       309\n",
      "      International       0.66      0.35      0.46       128\n",
      "               Jazz       0.77      0.43      0.55        47\n",
      "Old-Time / Historic       0.90      0.96      0.93        55\n",
      "                Pop       0.17      0.04      0.07       204\n",
      "               Rock       0.74      0.89      0.81      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.64      0.45      0.53        31\n",
      "\n",
      "          micro avg       0.68      0.68      0.68      3866\n",
      "          macro avg       0.46      0.40      0.42      3866\n",
      "       weighted avg       0.63      0.68      0.64      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CENS CQT\n",
      "Training Report\n",
      "0.833447215579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.20      0.33        97\n",
      "          Classical       0.93      0.92      0.93      1143\n",
      "            Country       1.00      0.19      0.32       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.79      0.92      0.85      8533\n",
      "               Folk       0.81      0.78      0.80      2504\n",
      "            Hip-Hop       0.86      0.78      0.82      3229\n",
      "       Instrumental       0.88      0.65      0.75      1770\n",
      "      International       0.91      0.62      0.74      1261\n",
      "               Jazz       0.91      0.55      0.68       524\n",
      "Old-Time / Historic       1.00      0.98      0.99       499\n",
      "                Pop       0.92      0.38      0.54      2128\n",
      "               Rock       0.84      0.94      0.89     12718\n",
      "           Soul-RnB       1.00      0.05      0.10       132\n",
      "             Spoken       0.77      0.74      0.76       392\n",
      "\n",
      "          micro avg       0.83      0.83      0.83     35124\n",
      "          macro avg       0.84      0.58      0.63     35124\n",
      "       weighted avg       0.84      0.83      0.82     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.656751163994\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.72      0.68      0.70        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.59      0.85      0.70       839\n",
      "               Folk       0.39      0.32      0.35       299\n",
      "            Hip-Hop       0.76      0.66      0.71       323\n",
      "       Instrumental       0.48      0.17      0.25       309\n",
      "      International       0.79      0.26      0.39       128\n",
      "               Jazz       0.76      0.47      0.58        47\n",
      "Old-Time / Historic       0.84      0.98      0.91        55\n",
      "                Pop       0.12      0.02      0.04       204\n",
      "               Rock       0.73      0.87      0.79      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.74      0.55      0.63        31\n",
      "\n",
      "          micro avg       0.66      0.66      0.66      3866\n",
      "          macro avg       0.46      0.39      0.40      3866\n",
      "       weighted avg       0.61      0.66      0.61      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CENT CENS CQT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CENS, CQT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENS CQT\n",
      "Training Report\n",
      "0.854942489466\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.29      0.45        97\n",
      "          Classical       0.95      0.94      0.94      1143\n",
      "            Country       1.00      0.25      0.40       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.82      0.94      0.87      8533\n",
      "               Folk       0.83      0.81      0.82      2504\n",
      "            Hip-Hop       0.87      0.82      0.84      3229\n",
      "       Instrumental       0.90      0.67      0.77      1770\n",
      "      International       0.92      0.68      0.78      1261\n",
      "               Jazz       0.92      0.60      0.73       524\n",
      "Old-Time / Historic       1.00      0.99      0.99       499\n",
      "                Pop       0.92      0.44      0.60      2128\n",
      "               Rock       0.85      0.95      0.90     12718\n",
      "           Soul-RnB       1.00      0.09      0.17       132\n",
      "             Spoken       0.80      0.82      0.81       392\n",
      "\n",
      "          micro avg       0.85      0.85      0.85     35124\n",
      "          macro avg       0.85      0.62      0.67     35124\n",
      "       weighted avg       0.86      0.85      0.85     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.66606311433\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.78      0.71      0.75        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.62      0.85      0.72       839\n",
      "               Folk       0.35      0.30      0.33       299\n",
      "            Hip-Hop       0.76      0.69      0.72       323\n",
      "       Instrumental       0.54      0.17      0.25       309\n",
      "      International       0.79      0.34      0.48       128\n",
      "               Jazz       0.85      0.49      0.62        47\n",
      "Old-Time / Historic       0.87      0.96      0.91        55\n",
      "                Pop       0.15      0.04      0.06       204\n",
      "               Rock       0.73      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.71      0.55      0.62        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.48      0.40      0.42      3866\n",
      "       weighted avg       0.62      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENS CQT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENS, CQT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT CENS CQT\n",
      "Training Report\n",
      "0.857220134381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.29      0.45        97\n",
      "          Classical       0.95      0.94      0.94      1143\n",
      "            Country       1.00      0.26      0.41       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.82      0.94      0.88      8533\n",
      "               Folk       0.83      0.81      0.82      2504\n",
      "            Hip-Hop       0.88      0.82      0.84      3229\n",
      "       Instrumental       0.91      0.68      0.77      1770\n",
      "      International       0.92      0.69      0.78      1261\n",
      "               Jazz       0.93      0.61      0.74       524\n",
      "Old-Time / Historic       1.00      0.99      0.99       499\n",
      "                Pop       0.92      0.45      0.60      2128\n",
      "               Rock       0.86      0.95      0.90     12718\n",
      "           Soul-RnB       1.00      0.11      0.19       132\n",
      "             Spoken       0.81      0.83      0.82       392\n",
      "\n",
      "          micro avg       0.86      0.86      0.86     35124\n",
      "          macro avg       0.85      0.62      0.68     35124\n",
      "       weighted avg       0.86      0.86      0.85     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.666839110191\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.78      0.71      0.75        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.62      0.85      0.72       839\n",
      "               Folk       0.35      0.29      0.32       299\n",
      "            Hip-Hop       0.76      0.69      0.73       323\n",
      "       Instrumental       0.56      0.18      0.27       309\n",
      "      International       0.78      0.33      0.46       128\n",
      "               Jazz       0.82      0.49      0.61        47\n",
      "Old-Time / Historic       0.87      0.96      0.91        55\n",
      "                Pop       0.17      0.04      0.07       204\n",
      "               Rock       0.73      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.71      0.55      0.62        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.48      0.40      0.42      3866\n",
      "       weighted avg       0.63      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT CENS CQT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, CENS, CQT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC TON\n",
      "Training Report\n",
      "0.843184147591\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.31      0.47        97\n",
      "          Classical       0.95      0.92      0.93      1143\n",
      "            Country       1.00      0.27      0.43       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.79      0.92      0.85      8533\n",
      "               Folk       0.82      0.79      0.81      2504\n",
      "            Hip-Hop       0.86      0.78      0.82      3229\n",
      "       Instrumental       0.85      0.66      0.74      1770\n",
      "      International       0.92      0.65      0.76      1261\n",
      "               Jazz       0.92      0.60      0.72       524\n",
      "Old-Time / Historic       1.00      0.99      0.99       499\n",
      "                Pop       0.92      0.43      0.59      2128\n",
      "               Rock       0.85      0.94      0.90     12718\n",
      "           Soul-RnB       1.00      0.13      0.23       132\n",
      "             Spoken       0.86      0.84      0.85       392\n",
      "\n",
      "          micro avg       0.84      0.84      0.84     35124\n",
      "          macro avg       0.85      0.62      0.67     35124\n",
      "       weighted avg       0.85      0.84      0.83     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.664769787894\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.76      0.80      0.78        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.61      0.84      0.70       839\n",
      "               Folk       0.41      0.33      0.37       299\n",
      "            Hip-Hop       0.74      0.69      0.71       323\n",
      "       Instrumental       0.47      0.17      0.26       309\n",
      "      International       0.72      0.34      0.46       128\n",
      "               Jazz       0.81      0.45      0.58        47\n",
      "Old-Time / Historic       0.78      0.98      0.87        55\n",
      "                Pop       0.09      0.02      0.03       204\n",
      "               Rock       0.74      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.67      0.45      0.54        31\n",
      "\n",
      "          micro avg       0.66      0.66      0.66      3866\n",
      "          macro avg       0.45      0.40      0.41      3866\n",
      "       weighted avg       0.62      0.66      0.62      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC TON\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, TON])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC ZCR\n",
      "Training Report\n",
      "0.817873818472\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.27      0.42        97\n",
      "          Classical       0.94      0.91      0.92      1143\n",
      "            Country       1.00      0.25      0.40       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.76      0.91      0.83      8533\n",
      "               Folk       0.79      0.75      0.77      2504\n",
      "            Hip-Hop       0.84      0.74      0.79      3229\n",
      "       Instrumental       0.80      0.58      0.67      1770\n",
      "      International       0.91      0.61      0.73      1261\n",
      "               Jazz       0.91      0.51      0.65       524\n",
      "Old-Time / Historic       0.99      0.99      0.99       499\n",
      "                Pop       0.90      0.37      0.53      2128\n",
      "               Rock       0.83      0.94      0.88     12718\n",
      "           Soul-RnB       1.00      0.11      0.19       132\n",
      "             Spoken       0.83      0.77      0.80       392\n",
      "\n",
      "          micro avg       0.82      0.82      0.82     35124\n",
      "          macro avg       0.83      0.58      0.64     35124\n",
      "       weighted avg       0.83      0.82      0.81     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.659855147439\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.68      0.75      0.71        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.61      0.83      0.71       839\n",
      "               Folk       0.36      0.26      0.31       299\n",
      "            Hip-Hop       0.71      0.68      0.69       323\n",
      "       Instrumental       0.50      0.21      0.29       309\n",
      "      International       0.64      0.29      0.40       128\n",
      "               Jazz       0.75      0.38      0.51        47\n",
      "Old-Time / Historic       0.82      0.96      0.88        55\n",
      "                Pop       0.17      0.03      0.05       204\n",
      "               Rock       0.73      0.89      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.71      0.39      0.50        31\n",
      "\n",
      "          micro avg       0.66      0.66      0.66      3866\n",
      "          macro avg       0.45      0.38      0.39      3866\n",
      "       weighted avg       0.61      0.66      0.62      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC ZCR\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, ZCR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT TON\n",
      "Training Report\n",
      "0.866188361234\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.38      0.55        97\n",
      "          Classical       0.97      0.94      0.95      1143\n",
      "            Country       1.00      0.38      0.55       176\n",
      "     Easy Listening       1.00      0.06      0.11        18\n",
      "         Electronic       0.83      0.94      0.88      8533\n",
      "               Folk       0.84      0.82      0.83      2504\n",
      "            Hip-Hop       0.89      0.82      0.86      3229\n",
      "       Instrumental       0.88      0.69      0.77      1770\n",
      "      International       0.93      0.72      0.81      1261\n",
      "               Jazz       0.96      0.67      0.79       524\n",
      "Old-Time / Historic       1.00      0.99      1.00       499\n",
      "                Pop       0.93      0.50      0.65      2128\n",
      "               Rock       0.87      0.95      0.91     12718\n",
      "           Soul-RnB       1.00      0.20      0.33       132\n",
      "             Spoken       0.85      0.89      0.87       392\n",
      "\n",
      "          micro avg       0.87      0.87      0.87     35124\n",
      "          macro avg       0.93      0.66      0.72     35124\n",
      "       weighted avg       0.87      0.87      0.86     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.674340403518\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.84      0.87      0.86        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.64      0.85      0.73       839\n",
      "               Folk       0.36      0.30      0.33       299\n",
      "            Hip-Hop       0.74      0.72      0.73       323\n",
      "       Instrumental       0.55      0.20      0.29       309\n",
      "      International       0.71      0.37      0.48       128\n",
      "               Jazz       0.81      0.47      0.59        47\n",
      "Old-Time / Historic       0.88      0.96      0.92        55\n",
      "                Pop       0.09      0.02      0.04       204\n",
      "               Rock       0.74      0.89      0.81      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.59      0.42      0.49        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.42      3866\n",
      "       weighted avg       0.63      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT TON\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, TON])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT ZCR\n",
      "Training Report\n",
      "0.850216376267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.34      0.51        97\n",
      "          Classical       0.96      0.92      0.94      1143\n",
      "            Country       1.00      0.35      0.52       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.81      0.93      0.86      8533\n",
      "               Folk       0.82      0.79      0.80      2504\n",
      "            Hip-Hop       0.87      0.80      0.83      3229\n",
      "       Instrumental       0.86      0.65      0.74      1770\n",
      "      International       0.93      0.67      0.78      1261\n",
      "               Jazz       0.94      0.61      0.74       524\n",
      "Old-Time / Historic       1.00      0.99      1.00       499\n",
      "                Pop       0.91      0.45      0.61      2128\n",
      "               Rock       0.86      0.95      0.90     12718\n",
      "           Soul-RnB       1.00      0.19      0.32       132\n",
      "             Spoken       0.84      0.85      0.85       392\n",
      "\n",
      "          micro avg       0.85      0.85      0.85     35124\n",
      "          macro avg       0.85      0.63      0.69     35124\n",
      "       weighted avg       0.86      0.85      0.84     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.673305742369\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.77      0.83      0.80        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.64      0.84      0.73       839\n",
      "               Folk       0.37      0.29      0.33       299\n",
      "            Hip-Hop       0.71      0.71      0.71       323\n",
      "       Instrumental       0.54      0.21      0.31       309\n",
      "      International       0.68      0.35      0.46       128\n",
      "               Jazz       0.80      0.43      0.56        47\n",
      "Old-Time / Historic       0.90      0.96      0.93        55\n",
      "                Pop       0.16      0.05      0.07       204\n",
      "               Rock       0.74      0.89      0.81      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.59      0.42      0.49        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.41      3866\n",
      "       weighted avg       0.63      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT ZCR\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, ZCR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT TON ZCR\n",
      "Training Report\n",
      "0.868295182781\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.38      0.55        97\n",
      "          Classical       0.97      0.94      0.95      1143\n",
      "            Country       1.00      0.39      0.56       176\n",
      "     Easy Listening       1.00      0.06      0.11        18\n",
      "         Electronic       0.83      0.94      0.88      8533\n",
      "               Folk       0.84      0.82      0.83      2504\n",
      "            Hip-Hop       0.89      0.83      0.86      3229\n",
      "       Instrumental       0.89      0.69      0.78      1770\n",
      "      International       0.93      0.72      0.81      1261\n",
      "               Jazz       0.96      0.67      0.79       524\n",
      "Old-Time / Historic       1.00      0.99      1.00       499\n",
      "                Pop       0.92      0.50      0.65      2128\n",
      "               Rock       0.87      0.96      0.91     12718\n",
      "           Soul-RnB       0.96      0.19      0.32       132\n",
      "             Spoken       0.85      0.88      0.86       392\n",
      "\n",
      "          micro avg       0.87      0.87      0.87     35124\n",
      "          macro avg       0.93      0.66      0.72     35124\n",
      "       weighted avg       0.87      0.87      0.86     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.675892395241\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.84      0.83      0.83        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.64      0.85      0.73       839\n",
      "               Folk       0.36      0.29      0.32       299\n",
      "            Hip-Hop       0.74      0.72      0.73       323\n",
      "       Instrumental       0.54      0.19      0.28       309\n",
      "      International       0.72      0.37      0.49       128\n",
      "               Jazz       0.79      0.47      0.59        47\n",
      "Old-Time / Historic       0.87      0.96      0.91        55\n",
      "                Pop       0.14      0.04      0.06       204\n",
      "               Rock       0.74      0.89      0.81      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.59      0.42      0.49        31\n",
      "\n",
      "          micro avg       0.68      0.68      0.68      3866\n",
      "          macro avg       0.46      0.40      0.42      3866\n",
      "       weighted avg       0.63      0.68      0.64      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT TON ZCR\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, TON, ZCR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT CENS CQT TON\n",
      "Training Report\n",
      "0.863626010705\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.31      0.47        97\n",
      "          Classical       0.96      0.94      0.95      1143\n",
      "            Country       1.00      0.27      0.43       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.83      0.94      0.88      8533\n",
      "               Folk       0.84      0.82      0.83      2504\n",
      "            Hip-Hop       0.88      0.82      0.85      3229\n",
      "       Instrumental       0.91      0.69      0.79      1770\n",
      "      International       0.91      0.70      0.79      1261\n",
      "               Jazz       0.95      0.63      0.75       524\n",
      "Old-Time / Historic       1.00      1.00      1.00       499\n",
      "                Pop       0.92      0.47      0.63      2128\n",
      "               Rock       0.86      0.96      0.91     12718\n",
      "           Soul-RnB       1.00      0.14      0.24       132\n",
      "             Spoken       0.82      0.84      0.83       392\n",
      "\n",
      "          micro avg       0.86      0.86      0.86     35124\n",
      "          macro avg       0.86      0.64      0.69     35124\n",
      "       weighted avg       0.87      0.86      0.86     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.667097775479\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.77      0.75      0.76        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.62      0.85      0.72       839\n",
      "               Folk       0.38      0.33      0.36       299\n",
      "            Hip-Hop       0.75      0.69      0.72       323\n",
      "       Instrumental       0.52      0.17      0.25       309\n",
      "      International       0.74      0.34      0.46       128\n",
      "               Jazz       0.77      0.49      0.60        47\n",
      "Old-Time / Historic       0.87      0.96      0.91        55\n",
      "                Pop       0.13      0.03      0.05       204\n",
      "               Rock       0.74      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.64      0.52      0.57        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.41      3866\n",
      "       weighted avg       0.62      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT CENS CQT TON\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, CENS, CQT, TON])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT CENS CQT ZCR\n",
      "Training Report\n",
      "0.858842956383\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.29      0.45        97\n",
      "          Classical       0.95      0.94      0.94      1143\n",
      "            Country       1.00      0.30      0.46       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.82      0.94      0.88      8533\n",
      "               Folk       0.83      0.81      0.82      2504\n",
      "            Hip-Hop       0.88      0.82      0.84      3229\n",
      "       Instrumental       0.91      0.68      0.78      1770\n",
      "      International       0.92      0.69      0.79      1261\n",
      "               Jazz       0.93      0.62      0.74       524\n",
      "Old-Time / Historic       1.00      0.99      1.00       499\n",
      "                Pop       0.92      0.46      0.61      2128\n",
      "               Rock       0.86      0.95      0.90     12718\n",
      "           Soul-RnB       1.00      0.11      0.19       132\n",
      "             Spoken       0.81      0.83      0.82       392\n",
      "\n",
      "          micro avg       0.86      0.86      0.86     35124\n",
      "          macro avg       0.86      0.63      0.68     35124\n",
      "       weighted avg       0.86      0.86      0.85     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.667097775479\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.77      0.70      0.73        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.63      0.86      0.72       839\n",
      "               Folk       0.35      0.30      0.32       299\n",
      "            Hip-Hop       0.75      0.69      0.72       323\n",
      "       Instrumental       0.52      0.17      0.26       309\n",
      "      International       0.75      0.33      0.46       128\n",
      "               Jazz       0.79      0.49      0.61        47\n",
      "Old-Time / Historic       0.88      0.96      0.92        55\n",
      "                Pop       0.18      0.04      0.07       204\n",
      "               Rock       0.73      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.71      0.55      0.62        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.47      0.40      0.42      3866\n",
      "       weighted avg       0.62      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT CENS CQT ZCR\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, CENS, CQT, ZCR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT CENS CQT TON ZCR\n",
      "Training Report\n",
      "0.865476597198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.31      0.47        97\n",
      "          Classical       0.95      0.94      0.95      1143\n",
      "            Country       1.00      0.28      0.44       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.83      0.94      0.88      8533\n",
      "               Folk       0.84      0.82      0.83      2504\n",
      "            Hip-Hop       0.88      0.83      0.85      3229\n",
      "       Instrumental       0.91      0.69      0.79      1770\n",
      "      International       0.91      0.70      0.79      1261\n",
      "               Jazz       0.94      0.63      0.76       524\n",
      "Old-Time / Historic       1.00      0.99      0.99       499\n",
      "                Pop       0.92      0.48      0.63      2128\n",
      "               Rock       0.87      0.96      0.91     12718\n",
      "           Soul-RnB       1.00      0.15      0.26       132\n",
      "             Spoken       0.81      0.85      0.83       392\n",
      "\n",
      "          micro avg       0.87      0.87      0.87     35124\n",
      "          macro avg       0.86      0.64      0.69     35124\n",
      "       weighted avg       0.87      0.87      0.86     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.66606311433\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.78      0.74      0.76        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.62      0.85      0.72       839\n",
      "               Folk       0.38      0.33      0.35       299\n",
      "            Hip-Hop       0.76      0.69      0.72       323\n",
      "       Instrumental       0.48      0.16      0.24       309\n",
      "      International       0.75      0.34      0.46       128\n",
      "               Jazz       0.74      0.49      0.59        47\n",
      "Old-Time / Historic       0.87      0.96      0.91        55\n",
      "                Pop       0.13      0.03      0.05       204\n",
      "               Rock       0.73      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.68      0.55      0.61        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.41      3866\n",
      "       weighted avg       0.62      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT CENS CQT TON ZCR\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, CENS, CQT, TON, ZCR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENS,CQT,STFT,MFCC,RMSE,BW,CENT,CONT,ROLLOFF,TON,ZCR\n",
      "Training Report\n",
      "0.863882245758\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.30      0.46        97\n",
      "          Classical       0.95      0.94      0.94      1143\n",
      "            Country       1.00      0.22      0.36       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.83      0.94      0.88      8533\n",
      "               Folk       0.84      0.83      0.83      2504\n",
      "            Hip-Hop       0.89      0.82      0.86      3229\n",
      "       Instrumental       0.91      0.69      0.78      1770\n",
      "      International       0.91      0.70      0.79      1261\n",
      "               Jazz       0.94      0.62      0.75       524\n",
      "Old-Time / Historic       1.00      0.99      0.99       499\n",
      "                Pop       0.92      0.48      0.63      2128\n",
      "               Rock       0.86      0.96      0.91     12718\n",
      "           Soul-RnB       1.00      0.12      0.22       132\n",
      "             Spoken       0.80      0.85      0.82       392\n",
      "\n",
      "          micro avg       0.86      0.86      0.86     35124\n",
      "          macro avg       0.86      0.63      0.68     35124\n",
      "       weighted avg       0.87      0.86      0.86     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.66787377134\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.77      0.67      0.72        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.62      0.87      0.72       839\n",
      "               Folk       0.36      0.31      0.34       299\n",
      "            Hip-Hop       0.78      0.72      0.75       323\n",
      "       Instrumental       0.49      0.16      0.24       309\n",
      "      International       0.75      0.31      0.44       128\n",
      "               Jazz       0.73      0.51      0.60        47\n",
      "Old-Time / Historic       0.89      0.98      0.93        55\n",
      "                Pop       0.11      0.02      0.04       204\n",
      "               Rock       0.73      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.66      0.61      0.63        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.41      3866\n",
      "       weighted avg       0.62      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"CENS,CQT,STFT,MFCC,RMSE,BW,CENT,CONT,ROLLOFF,TON,ZCR\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([CENS,CQT,STFT,MFCC,RMSE,BW,CENT,CONT,ROLLOFF,TON,ZCR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT CENS CQT STFT ROLLOFF\n",
      "Training Report\n",
      "0.859839426033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.29      0.45        97\n",
      "          Classical       0.95      0.94      0.94      1143\n",
      "            Country       1.00      0.22      0.36       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.82      0.94      0.88      8533\n",
      "               Folk       0.83      0.82      0.83      2504\n",
      "            Hip-Hop       0.88      0.82      0.85      3229\n",
      "       Instrumental       0.91      0.68      0.78      1770\n",
      "      International       0.91      0.69      0.78      1261\n",
      "               Jazz       0.93      0.61      0.74       524\n",
      "Old-Time / Historic       1.00      0.99      0.99       499\n",
      "                Pop       0.93      0.46      0.62      2128\n",
      "               Rock       0.86      0.95      0.90     12718\n",
      "           Soul-RnB       1.00      0.12      0.22       132\n",
      "             Spoken       0.79      0.83      0.81       392\n",
      "\n",
      "          micro avg       0.86      0.86      0.86     35124\n",
      "          macro avg       0.85      0.62      0.68     35124\n",
      "       weighted avg       0.87      0.86      0.85     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.668391101914\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.77      0.68      0.72        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.62      0.86      0.72       839\n",
      "               Folk       0.37      0.32      0.34       299\n",
      "            Hip-Hop       0.76      0.70      0.73       323\n",
      "       Instrumental       0.55      0.17      0.25       309\n",
      "      International       0.77      0.31      0.44       128\n",
      "               Jazz       0.75      0.51      0.61        47\n",
      "Old-Time / Historic       0.89      0.98      0.93        55\n",
      "                Pop       0.07      0.01      0.02       204\n",
      "               Rock       0.73      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.67      0.65      0.66        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.42      3866\n",
      "       weighted avg       0.62      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT CENS CQT STFT ROLLOFF\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, CENS, CQT, TON, STFT, ROLLOFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT STFT ROLLOFF\n",
      "Training Report\n",
      "0.843611206013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.32      0.48        97\n",
      "          Classical       0.96      0.92      0.94      1143\n",
      "            Country       1.00      0.28      0.44       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.80      0.93      0.86      8533\n",
      "               Folk       0.81      0.79      0.80      2504\n",
      "            Hip-Hop       0.86      0.79      0.82      3229\n",
      "       Instrumental       0.87      0.64      0.73      1770\n",
      "      International       0.92      0.65      0.76      1261\n",
      "               Jazz       0.92      0.59      0.72       524\n",
      "Old-Time / Historic       1.00      0.99      1.00       499\n",
      "                Pop       0.91      0.43      0.58      2128\n",
      "               Rock       0.85      0.95      0.89     12718\n",
      "           Soul-RnB       1.00      0.07      0.13       132\n",
      "             Spoken       0.81      0.81      0.81       392\n",
      "\n",
      "          micro avg       0.84      0.84      0.84     35124\n",
      "          macro avg       0.85      0.61      0.66     35124\n",
      "       weighted avg       0.85      0.84      0.83     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.672788411795\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.73      0.72      0.73        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.64      0.86      0.73       839\n",
      "               Folk       0.37      0.30      0.34       299\n",
      "            Hip-Hop       0.75      0.72      0.74       323\n",
      "       Instrumental       0.56      0.19      0.29       309\n",
      "      International       0.70      0.34      0.46       128\n",
      "               Jazz       0.73      0.51      0.60        47\n",
      "Old-Time / Historic       0.90      0.98      0.94        55\n",
      "                Pop       0.16      0.03      0.05       204\n",
      "               Rock       0.73      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.64      0.52      0.57        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.42      3866\n",
      "       weighted avg       0.63      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT STFT ROLLOFF\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, STFT, ROLLOFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT STFT\n",
      "Training Report\n",
      "0.843810499943\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.30      0.46        97\n",
      "          Classical       0.96      0.92      0.94      1143\n",
      "            Country       1.00      0.28      0.44       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.80      0.93      0.86      8533\n",
      "               Folk       0.81      0.80      0.80      2504\n",
      "            Hip-Hop       0.86      0.79      0.82      3229\n",
      "       Instrumental       0.87      0.64      0.74      1770\n",
      "      International       0.92      0.65      0.76      1261\n",
      "               Jazz       0.92      0.58      0.71       524\n",
      "Old-Time / Historic       1.00      0.99      0.99       499\n",
      "                Pop       0.90      0.43      0.58      2128\n",
      "               Rock       0.85      0.95      0.89     12718\n",
      "           Soul-RnB       1.00      0.08      0.14       132\n",
      "             Spoken       0.82      0.81      0.82       392\n",
      "\n",
      "          micro avg       0.84      0.84      0.84     35124\n",
      "          macro avg       0.85      0.61      0.66     35124\n",
      "       weighted avg       0.85      0.84      0.83     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.673047077082\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.74      0.72      0.73        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.63      0.86      0.73       839\n",
      "               Folk       0.38      0.32      0.35       299\n",
      "            Hip-Hop       0.76      0.71      0.73       323\n",
      "       Instrumental       0.53      0.19      0.28       309\n",
      "      International       0.70      0.34      0.46       128\n",
      "               Jazz       0.75      0.51      0.61        47\n",
      "Old-Time / Historic       0.84      0.98      0.91        55\n",
      "                Pop       0.16      0.03      0.05       204\n",
      "               Rock       0.73      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.64      0.52      0.57        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.41      3866\n",
      "       weighted avg       0.63      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT STFT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, STFT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT ROLLOFF\n",
      "Training Report\n",
      "0.848365789773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.38      0.55        97\n",
      "          Classical       0.96      0.92      0.94      1143\n",
      "            Country       1.00      0.33      0.50       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.80      0.93      0.86      8533\n",
      "               Folk       0.81      0.79      0.80      2504\n",
      "            Hip-Hop       0.87      0.79      0.83      3229\n",
      "       Instrumental       0.85      0.65      0.74      1770\n",
      "      International       0.93      0.67      0.78      1261\n",
      "               Jazz       0.94      0.60      0.73       524\n",
      "Old-Time / Historic       1.00      0.99      1.00       499\n",
      "                Pop       0.91      0.45      0.60      2128\n",
      "               Rock       0.85      0.95      0.90     12718\n",
      "           Soul-RnB       1.00      0.15      0.26       132\n",
      "             Spoken       0.84      0.85      0.84       392\n",
      "\n",
      "          micro avg       0.85      0.85      0.85     35124\n",
      "          macro avg       0.85      0.63      0.69     35124\n",
      "       weighted avg       0.85      0.85      0.84     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.674081738231\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.78      0.80      0.79        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.64      0.84      0.73       839\n",
      "               Folk       0.37      0.27      0.31       299\n",
      "            Hip-Hop       0.72      0.72      0.72       323\n",
      "       Instrumental       0.53      0.22      0.31       309\n",
      "      International       0.67      0.36      0.47       128\n",
      "               Jazz       0.76      0.40      0.53        47\n",
      "Old-Time / Historic       0.93      0.96      0.95        55\n",
      "                Pop       0.16      0.04      0.07       204\n",
      "               Rock       0.74      0.89      0.81      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.64      0.45      0.53        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.41      3866\n",
      "       weighted avg       0.63      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT ROLLOFF\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, ROLLOFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CONT CENT CENS CQT TON CQT STFT ROLLOFF\n",
      "Training Report\n",
      "0.859839426033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.29      0.45        97\n",
      "          Classical       0.95      0.94      0.94      1143\n",
      "            Country       1.00      0.22      0.36       176\n",
      "     Easy Listening       0.00      0.00      0.00        18\n",
      "         Electronic       0.82      0.94      0.88      8533\n",
      "               Folk       0.83      0.82      0.83      2504\n",
      "            Hip-Hop       0.88      0.82      0.85      3229\n",
      "       Instrumental       0.91      0.68      0.78      1770\n",
      "      International       0.91      0.69      0.78      1261\n",
      "               Jazz       0.93      0.61      0.74       524\n",
      "Old-Time / Historic       1.00      0.99      0.99       499\n",
      "                Pop       0.93      0.46      0.62      2128\n",
      "               Rock       0.86      0.95      0.90     12718\n",
      "           Soul-RnB       1.00      0.12      0.22       132\n",
      "             Spoken       0.79      0.83      0.81       392\n",
      "\n",
      "          micro avg       0.86      0.86      0.86     35124\n",
      "          macro avg       0.85      0.62      0.68     35124\n",
      "       weighted avg       0.87      0.86      0.85     35124\n",
      "\n",
      "\n",
      "Test Report\n",
      "0.668391101914\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.00      0.00      0.00        13\n",
      "          Classical       0.77      0.68      0.72        87\n",
      "            Country       0.00      0.00      0.00        18\n",
      "     Easy Listening       0.00      0.00      0.00         6\n",
      "         Electronic       0.62      0.86      0.72       839\n",
      "               Folk       0.37      0.32      0.34       299\n",
      "            Hip-Hop       0.76      0.70      0.73       323\n",
      "       Instrumental       0.55      0.17      0.25       309\n",
      "      International       0.77      0.31      0.44       128\n",
      "               Jazz       0.75      0.51      0.61        47\n",
      "Old-Time / Historic       0.89      0.98      0.93        55\n",
      "                Pop       0.07      0.01      0.02       204\n",
      "               Rock       0.73      0.88      0.80      1464\n",
      "           Soul-RnB       0.00      0.00      0.00        43\n",
      "             Spoken       0.67      0.65      0.66        31\n",
      "\n",
      "          micro avg       0.67      0.67      0.67      3866\n",
      "          macro avg       0.46      0.40      0.42      3866\n",
      "       weighted avg       0.62      0.67      0.63      3866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#rbf c = 1.5\n",
    "print(\"MFCC CONT CENT CENS CQT TON CQT STFT ROLLOFF\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CONT, CENT, CENS, CQT, TON, CQT,  STFT, ROLLOFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.998661883612\n",
      "\n",
      "\n",
      "Test Accuracy:  0.653388515261\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 10, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.99880423642\n",
      "\n",
      "\n",
      "Test Accuracy:  0.653905845835\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 100, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1000, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.705329689101\n",
      "\n",
      "\n",
      "Test Accuracy:  0.660889808588\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.792193372053\n",
      "\n",
      "\n",
      "Test Accuracy:  0.670460424211\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 10, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.935770413393\n",
      "\n",
      "\n",
      "Test Accuracy:  0.6526125194\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 100, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.998377177998\n",
      "\n",
      "\n",
      "Test Accuracy:  0.627521986549\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1000, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.647505978818\n",
      "\n",
      "\n",
      "Test Accuracy:  0.626228660114\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.690040997608\n",
      "\n",
      "\n",
      "Test Accuracy:  0.653647180548\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 10, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.725856963899\n",
      "\n",
      "\n",
      "Test Accuracy:  0.66244180031\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 100, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.800279011502\n",
      "\n",
      "\n",
      "Test Accuracy:  0.66244180031\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1000, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.780577382986\n",
      "\n",
      "\n",
      "Test Accuracy:  0.668908432488\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 8, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.814571233345\n",
      "\n",
      "\n",
      "Test Accuracy:  0.669943093637\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 15, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.832023687507\n",
      "\n",
      "\n",
      "Test Accuracy:  0.668132436627\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 20, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.846458262157\n",
      "\n",
      "\n",
      "Test Accuracy:  0.668391101914\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 25, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.877348821319\n",
      "\n",
      "\n",
      "Test Accuracy:  0.666580444904\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 40, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.716233914133\n",
      "\n",
      "\n",
      "Test Accuracy:  0.659079151578\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 60, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.541196902403\n",
      "\n",
      "\n",
      "Test Accuracy:  0.538023797206\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.626039175493\n",
      "\n",
      "\n",
      "Test Accuracy:  0.606570098293\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 5, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.644658922674\n",
      "\n",
      "\n",
      "Test Accuracy:  0.62390067253\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 10, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.675264776221\n",
      "\n",
      "\n",
      "Test Accuracy:  0.648215209519\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 50, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.998604942489\n",
      "\n",
      "\n",
      "Test Accuracy:  0.379203310916\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.998690354174\n",
      "\n",
      "\n",
      "Test Accuracy:  0.379203310916\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.2, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.998747295297\n",
      "\n",
      "\n",
      "Test Accuracy:  0.379203310916\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.5, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.709344038264\n",
      "\n",
      "\n",
      "Test Accuracy:  0.379203310916\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 0.8, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.99880423642\n",
      "\n",
      "\n",
      "Test Accuracy:  0.379203310916\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 5, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.791567019702\n",
      "\n",
      "\n",
      "Test Accuracy:  0.673823072944\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 0.8, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.801987245188\n",
      "\n",
      "\n",
      "Test Accuracy:  0.673564407656\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 0.9, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.821147933037\n",
      "\n",
      "\n",
      "Test Accuracy:  0.676409725815\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.1, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.828180161713\n",
      "\n",
      "\n",
      "Test Accuracy:  0.677961717538\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.2, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.835724860494\n",
      "\n",
      "\n",
      "Test Accuracy:  0.67770305225\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.3, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.842842500854\n",
      "\n",
      "\n",
      "Test Accuracy:  0.677444386963\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.4, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.845746498121\n",
      "\n",
      "\n",
      "Test Accuracy:  0.676927056389\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.45, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.852351668375\n",
      "\n",
      "\n",
      "Test Accuracy:  0.676151060528\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.55, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE HOPEFUL ONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.830059218768\n",
      "\n",
      "\n",
      "Test Accuracy:  0.67770305225\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.22, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.18, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.827639221045\n",
      "\n",
      "\n",
      "Test Accuracy:  0.677444386963\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.19, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.829233572486\n",
      "\n",
      "\n",
      "Test Accuracy:  0.67770305225\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 1.21, \"auto_deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.802072656873\n",
      "\n",
      "\n",
      "Test Accuracy:  0.672012415934\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 12, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.796834073568\n",
      "\n",
      "\n",
      "Test Accuracy:  0.67149508536\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 11, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.799738070835\n",
      "\n",
      "\n",
      "Test Accuracy:  0.672788411795\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 11.5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.689642409748\n",
      "\n",
      "\n",
      "Test Accuracy:  0.651319192964\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 150, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n",
      "Train Accuracy:  0.696959344038\n",
      "\n",
      "\n",
      "Test Accuracy:  0.656492498707\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 300, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC CENT CONT\n"
     ]
    }
   ],
   "source": [
    "print(\"MFCC CENT CONT\")\n",
    "svm = SVM(tracks, features)\n",
    "svm.train([MFCC, CENT, CONT], 82000, 1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
